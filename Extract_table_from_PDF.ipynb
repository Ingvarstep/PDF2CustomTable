{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six #extract text and format\n",
        "!pip install pdfplumber #extract tables\n"
      ],
      "metadata": {
        "id": "-TBa1k69NxFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://s28.q4cdn.com/781576035/files/doc_financials/2022/ar/PFE-2022-Form-10K-FINAL-(without-Exhibits).pdf\" > pfizer-report.pdf"
      ],
      "metadata": {
        "id": "-R3lMYWgOPdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "from pdfminer.high_level import extract_pages, extract_text\n",
        "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
        "import pdfplumber\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re\n",
        "\n",
        "def normalize_text(line_texts):\n",
        "    norm_text = ''\n",
        "    for line_text in line_texts:\n",
        "        line_text=line_text.strip()\n",
        "        # empty strings after striping convert to newline character\n",
        "        if not line_text:\n",
        "            line_text = '\\n'\n",
        "        else:\n",
        "            line_text = re.sub('\\s+', ' ', line_text)\n",
        "            # if the last character is not a letter or number, add newline character to a line\n",
        "            if not re.search('[\\w\\d\\,\\-]', line_text[-1]):\n",
        "                line_text+='\\n'\n",
        "            else:\n",
        "                line_text+=' '\n",
        "        # concatenate into single string\n",
        "        norm_text+=line_text\n",
        "    return norm_text\n",
        "\n",
        "def text_extraction(element):\n",
        "    # Extract text from line and split it with new lines\n",
        "    line_texts = element.get_text().split('\\n')\n",
        "    line_text = normalize_text(line_texts)\n",
        "    return line_text\n",
        "\n",
        "def convert_table(table):\n",
        "    table_string = ''\n",
        "    # iterate through rows in the table\n",
        "    for row in table:\n",
        "        # clean row from newline character\n",
        "        cleaned_row = [\n",
        "            'None' if item is None else item.replace('\\n', ' ')\n",
        "            for item in row\n",
        "        ]\n",
        "        # concatenate the row as a string with the whole table\n",
        "        table_string += f\"|{'|'.join(cleaned_row)}|\\n\"\n",
        "    return table_string.rstrip('\\n')"
      ],
      "metadata": {
        "id": "f_mzmnqNejEi"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_page(page, extracted_page, text=True, table=True):\n",
        "    content = []\n",
        "\n",
        "    # Find the tables in the page\n",
        "    tables = page.find_tables()\n",
        "    extracted_tables = page.extract_tables()\n",
        "\n",
        "    table_num = 0\n",
        "    first_table_element = True\n",
        "    table_extraction_process = False\n",
        "\n",
        "    # Get a sorted list of elements based on their Y-coordinate in reverse order\n",
        "    elements = [element for element in extracted_page._objs]\n",
        "    elements.sort(key=lambda a: a.y1, reverse=True)\n",
        "\n",
        "    lower_side = 0\n",
        "    upper_side = 0\n",
        "    for i, element in enumerate(elements):\n",
        "        # Extract text if the element is a text container and text extraction is enabled\n",
        "        if isinstance(element, LTTextContainer) and not table_extraction_process and text:\n",
        "            line_text = text_extraction(element)\n",
        "            content.append(line_text)\n",
        "\n",
        "        # Process tables if the element is a rectangle and table extraction is enabled\n",
        "        if isinstance(element, LTRect) and table:\n",
        "            if first_table_element and table_num < len(tables):\n",
        "                lower_side = page.bbox[3] - tables[table_num].bbox[3]\n",
        "                upper_side = element.y1\n",
        "\n",
        "                table = extracted_tables[table_num]\n",
        "                table_string = convert_table(table)\n",
        "                content.append(table_string)\n",
        "                table_extraction_process = True\n",
        "                first_table_element = False\n",
        "\n",
        "            # Check if we have already extracted the tables from the page\n",
        "            if element.y0 >= lower_side and element.y1 <= upper_side:\n",
        "                pass\n",
        "            elif i + 1 >= len(elements):\n",
        "                pass\n",
        "            elif not isinstance(elements[i + 1], LTRect):\n",
        "                table_extraction_process = False\n",
        "                first_table_element = True\n",
        "                table_num += 1\n",
        "\n",
        "    # Combine and clean up the extracted content\n",
        "    content = re.sub('\\n+', '\\n', ''.join(content))\n",
        "    return content\n",
        "\n",
        "def process_document(pdf_path, text=True, table=True, page_ids=None):\n",
        "    pdf = pdfplumber.open(pdf_path)\n",
        "    pages = pdf.pages\n",
        "\n",
        "    # Extract pages from the PDF\n",
        "    extracted_pages = extract_pages(pdf_path, page_numbers=page_ids)\n",
        "\n",
        "    page2content = {}\n",
        "\n",
        "    # Process each extracted page\n",
        "    for extracted_page in tqdm(extracted_pages):\n",
        "        page_id = extracted_page.pageid\n",
        "        content = process_page(pages[page_id - 1], extracted_page, text, table)\n",
        "        page2content[page_id] = content\n",
        "\n",
        "    return page2content\n"
      ],
      "metadata": {
        "id": "otK0MDURtKTJ"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = 'pfizer-report.pdf'\n",
        "page2content = process_document(pdf_path, page_ids=[37])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n88u-w61cOk",
        "outputId": "8b751c1f-7d29-4305-cc95-297bad8a3d99"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  1.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "URL = \"https://text2table.p.rapidapi.com/text2table\"\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "headers = {\n",
        "\t\"content-type\": \"application/json\",\n",
        "\t\"X-RapidAPI-Key\": API_KEY,\n",
        "\t\"X-RapidAPI-Host\": \"text2table.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "def construct_table(text, columns):\n",
        "    payload = {\n",
        "        \"text\": text,\n",
        "        \"columns\": columns\n",
        "    }\n",
        "\n",
        "    response = requests.post(URL, json=payload, headers=headers)\n",
        "    result = response.json()\n",
        "    return result"
      ],
      "metadata": {
        "id": "TW1-Y1eT46qU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = page2content[1]\n",
        "columns = ['product', 'revenue', 'change', 'remark']\n",
        "table = construct_table(text, columns)\n",
        "df = pd.DataFrame(table)\n",
        "df.to_csv('pfizer_products_summary.csv')"
      ],
      "metadata": {
        "id": "MfWCB0TA9u41"
      },
      "execution_count": 213,
      "outputs": []
    }
  ]
}